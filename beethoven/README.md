# Beethoven - Indian Sign Language to English Voice Converter

An advanced Flutter application that uses machine learning to convert live Indian Sign Language (ISL) video from the camera into English voice. This is a research-grade ML-powered application built by an ML engineer with PhD credentials.

## ğŸ¯ Project Vision

To create an accessible, real-time translation system that bridges the communication gap between sign language users and English speakers through intelligent video analysis and natural voice synthesis.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Flutter Frontend                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Home Screen â†’ Camera Screen â†’ Recognition Display          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Video Processing Pipeline                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Camera Input â†’ Frame Preprocessing â†’ ML Inference          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           TensorFlow Lite Model Execution                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MediaPipe Pose Detection â†’ LSTM/3D-CNN â†’ Sign Classification
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Text-to-Speech with Indian Accent                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Google Cloud TTS API / Flutter TTS â†’ Audio Output          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Flutter**: >= 3.0.0
- **Dart**: >= 3.0.0
- **Python**: >= 3.8 (for model training)
- **TensorFlow**: >= 2.10
- **macOS/iOS/Android** device for testing

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/ABcDexter/Fun-with-Flutter.git
cd Fun-with-Flutter/beethoven
```

2. **Install Flutter dependencies**
```bash
flutter pub get
```

3. **Set up Python environment (for model training)**
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r scripts/requirements.txt
```

4. **Run the app**
```bash
flutter run
```

## ğŸ“‹ Project Structure

```
beethoven/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ main.dart                      # App entry point
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ constants.dart             # ML & app constants
â”‚   â”‚   â””â”€â”€ providers.dart             # Riverpod providers
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ camera/                    # Camera functionality
â”‚   â”‚   â”‚   â””â”€â”€ camera_screen.dart
â”‚   â”‚   â”œâ”€â”€ ml/                        # ML inference
â”‚   â”‚   â”‚   â””â”€â”€ isl_interpreter.dart
â”‚   â”‚   â”œâ”€â”€ recognition/               # Sign recognition
â”‚   â”‚   â”‚   â””â”€â”€ sign_recognizer.dart
â”‚   â”‚   â”œâ”€â”€ tts/                       # Text-to-speech
â”‚   â”‚   â”‚   â””â”€â”€ speech_service.dart
â”‚   â”‚   â””â”€â”€ ui/                        # UI screens
â”‚   â”‚       â””â”€â”€ home_screen.dart
â”‚   â”œâ”€â”€ models/                        # Data models
â”‚   â”‚   â””â”€â”€ recognition_models.dart
â”‚   â”œâ”€â”€ services/                      # Core services
â”‚   â”‚   â”œâ”€â”€ camera_service.dart
â”‚   â”‚   â”œâ”€â”€ ml_service.dart
â”‚   â”‚   â””â”€â”€ tts_service.dart
â”‚   â””â”€â”€ utils/                         # Utilities
â”‚       â””â”€â”€ extensions.dart
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_model.py                 # Model training
â”‚   â”œâ”€â”€ vocabulary.py                  # ISL vocabulary
â”‚   â”œâ”€â”€ recognition_engine.py          # Recognition logic
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ isl_recognition_model.tflite
â”‚   â”œâ”€â”€ data/
â”‚   â””â”€â”€ isl_vocabulary/
â”œâ”€â”€ pubspec.yaml                       # Flutter dependencies
â””â”€â”€ PROJECT_PLAN.md                    # Detailed project plan
```

## ğŸ¤– Machine Learning Pipeline

### Dataset
- **Source**: [ISLAR - Hugging Face](https://huggingface.co/datasets/akshaybahadur21/ISLAR)
- **Size**: 10,000+ ISL gesture videos
- **Classes**: 100 common ISL signs

### Model Training

#### Step 1: Download Dataset
```bash
cd scripts
python3 download_dataset.py
```

#### Step 2: Train Model
```bash
python3 train_model.py \
  --model_type lstm_mediapipe \
  --vocabulary_size 100 \
  --sequence_length 30 \
  --epochs 50
```

#### Step 3: Convert to TensorFlow Lite
The training script automatically converts to `.tflite` format optimized for mobile devices.

### Model Architecture Options

**Option 1: MediaPipe Pose + LSTM** (Recommended for Mobile)
- **Input**: Pose landmarks from 30 frames
- **Processing**: LSTM layers with attention
- **Output**: Sign classification (100 classes)
- **Advantages**: Lightweight, fast inference, robust to scale changes
- **Size**: ~10MB

**Option 2: 3D Convolutional Neural Network**
- **Input**: Stacked video frames (30 frames Ã— 224Ã—224)
- **Processing**: 3D convolutions + pooling
- **Output**: Sign classification
- **Advantages**: Better spatial-temporal understanding
- **Size**: ~50MB

### Model Performance Metrics

| Metric | Target | Expected |
|--------|--------|----------|
| Accuracy | 85%+ | 87-92% |
| Top-5 Accuracy | 95%+ | 96-98% |
| Inference Time | <500ms | 200-400ms |
| Model Size | <100MB | 10-50MB |
| RAM Usage | <300MB | 150-250MB |

## ğŸ¬ Features

### Current Implementation
- âœ… Real-time camera feed capture
- âœ… Frame preprocessing pipeline
- âœ… TensorFlow Lite model inference
- âœ… MediaPipe pose detection integration
- âœ… Text-to-Speech with Indian English accent
- âœ… Confidence scoring and visualization
- âœ… Translation history tracking

### Planned Features
- ğŸ”„ Multi-language support (Hindi, Punjabi, etc.)
- ğŸ”„ Sentence-level understanding
- ğŸ”„ Offline mode with cached TTS voices
- ğŸ”„ User profile and learning statistics
- ğŸ”„ Community-driven sign corrections
- ğŸ”„ Video recording with subtitles

## ğŸ“± Platform Support

| Platform | Status | Notes |
|----------|--------|-------|
| iOS | âœ… Ready | iOS 12+ required |
| Android | âœ… Ready | Android 8+ required |
| Web | ğŸ”„ In Progress | Camera limited on browsers |
| macOS | âœ… Ready | Development/Testing |
| Windows | ğŸ”„ Planned | Coming soon |
| Linux | ğŸ”„ Planned | Coming soon |

## ğŸ” API Integration

### Google Cloud Text-to-Speech
For natural-sounding Indian English voice synthesis:

```bash
# Set up credentials
export GOOGLE_APPLICATION_CREDENTIALS="path/to/credentials.json"
```

### Alternative: Microsoft Azure
For enterprise-grade speech synthesis with multiple Indian voices.

## ğŸ“Š Testing

### Unit Tests
```bash
flutter test
```

### Widget Tests
```bash
flutter test test/widget_test.dart
```

### Integration Tests
```bash
flutter drive --target=test_driver/app.dart
```

## ğŸ—ï¸ Build & Deployment

### Android Release Build
```bash
flutter build apk --release
# or for Android App Bundle
flutter build appbundle --release
```

### iOS Release Build
```bash
flutter build ios --release
```

### Web Build
```bash
flutter build web --release
```

## ğŸ“š Documentation

- **[PROJECT_PLAN.md](PROJECT_PLAN.md)** - Comprehensive technical specification
- **[Model Training Guide](scripts/train_model.py)** - Detailed training instructions
- **[API Documentation](lib/)** - Code API documentation

## ğŸ”¬ Research & References

### Key Papers
- Action Recognition in Videos (3D CNN)
- Sign Language Recognition with Pose Estimation
- Transformer-based Temporal Modeling for Action Recognition

### Datasets
- ISLAR (Indian Sign Language Action Recognition)
- ASL Dataset (for comparison)
- AUTSL (Ankara University Turkish Sign Language)

## ğŸ’¡ Technical Insights

### Why MediaPipe + LSTM for Mobile?
1. **Efficiency**: Pose detection is lightweight and fast
2. **Robustness**: Works across different body sizes and positions
3. **No redundancy**: Focuses on meaningful gesture information
4. **Scalability**: Easy to add new signs without retraining entire model

### Inference Pipeline Optimization
```
Frame Capture (30 FPS)
    â†“ (Skip 2/3 frames)
Pose Detection (10 FPS)
    â†“ (Every 30 frames = 3 seconds)
Model Inference
    â†“
Confidence Check
    â†“ (If >70%)
Text-to-Speech Generation
```

## ğŸ“ Academic Context

**Author Profile**: Deep interest in Machine Learning  
**Expertise**: 
- Deep Learning & Computer Vision
- Real-time Inference Systems
- Accessibility Technology

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ› Known Issues & Limitations

1. **Lighting Dependency**: Performance varies with lighting conditions
2. **Latency**: ~1-2 second delay between sign and speech output
3. **Vocabulary**: Limited to 100 most common ISL signs (expandable)
4. **Context**: No sentence-level understanding (sequential signs only)

## ğŸš¦ Roadmap

### Phase 1: MVP (Current)
- Basic sign recognition
- Real-time video processing
- TTS integration

### Phase 2: Enhancement
- Improved accuracy (>90%)
- Multiple language support
- Offline mode

### Phase 3: Advanced
- Sentence understanding
- AI-powered suggestions
- Community platform

## ğŸ“ Support

For issues, questions, or suggestions:
- ğŸ“§ Email: anubhav.balodhi@gmail.com
- ğŸ™ GitHub Issues: [Create an issue](https://github.com/ABcDexter/Fun-with-Flutter/issues)
- ğŸ’¬ Discussions: [Start a discussion](https://github.com/ABcDexter/Fun-with-Flutter/discussions)

---

**Status**: Under Active Development  
**Last Updated**: February 8, 2026  
**Version**: 0.1.0-alpha
